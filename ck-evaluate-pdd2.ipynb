{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdd_evaluate(inputs):\n",
    "    experiment, subject, sigma = inputs\n",
    "    import os.path as op\n",
    "    from glob import glob\n",
    "    import boto3\n",
    "    import numpy as np\n",
    "    from AFQ import registration as reg\n",
    "    import nibabel as nib\n",
    "    from subprocess import call\n",
    "    print(\"Subject ID: %s\"%subject)\n",
    "    \n",
    "    client = boto3.resource('s3')\n",
    "    bucket_name1 = 'arokem.mri2mri'\n",
    "    b1 = client.Bucket(bucket_name1)\n",
    "    ll1 = list(b1.objects.all())\n",
    "    bucket_name2 = 'arokem.mri2mri.dwi-predictions'\n",
    "    b2 = client.Bucket(bucket_name2)\n",
    "    ll2 = list(b2.objects.all())\n",
    "\n",
    "    print(\"Checking if outputs exist\")\n",
    "    exists = 0    \n",
    "    path = op.join(experiment, \n",
    "                   \"test_latest\", \n",
    "                   \"gaussian_%s\"%sigma)\n",
    "    \n",
    "    if op.join(path, \"%s_error_template.nii.gz\"%subject) in ll2:\n",
    "        exists = exists + 1\n",
    "    if op.join(path, \"%s_error_nn.nii.gz\"%subject) in ll2:\n",
    "        exists = exists + 1\n",
    "    \n",
    "    if exists == 2: \n",
    "        b2.download_file(op.join(path, \"%s_error_template.nii.gz\"%subject), \n",
    "                        'error_template.nii.gz')\n",
    "        b2.download_file(op.join(path, \"%s_error_nn.nii.gz\"%subject), \n",
    "                        'error_nn.nii.gz')\n",
    "        return nib.load(\"error_nn.nii.gz\").get_data(), nib.load(\"error_template.nii.gz\").get_data() \n",
    "\n",
    "    \n",
    "    print(\"Downloading IIT template data\")\n",
    "    b1.download_file(\"IIT-templates/IITmean_V1.nii.gz\", \"IITmean_V1.nii.gz\")\n",
    "    b1.download_file(\"IIT-templates/IITmean_t1.nii.gz\", \"IITmean_t1.nii.gz\")\n",
    "\n",
    "    print(\"Downloading T1 and DTI data\")\n",
    "    for l in ll1:\n",
    "        k = l.key\n",
    "        if k.startswith(\"IXI-T1\" ) and k.split('/')[-1].startswith(subject):\n",
    "            print(\"Downloading %s as T1\"%k)\n",
    "            b1.download_file(k, \"T1.nii.gz\")\n",
    "        if k.startswith(\"IXI-data/DTI\") and k.split('/')[-1].startswith(subject) and k.endswith(\"DTI-00.nii.gz\"):\n",
    "            print(\"Downloading %s as DTI\"%k)\n",
    "            b1.download_file(k, \"DTI-00.nii.gz\")\n",
    "\n",
    "    print(\"Downloading NPY files\")\n",
    "    for l in ll2: \n",
    "        k = l.key\n",
    "        if k.startswith(op.join(path, \"numpy\")) and op.split(k)[-1].startswith(subject):\n",
    "            print(\"Downloading %s\"%k)\n",
    "            b2.download_file(k, op.split(k)[-1])\n",
    "    \n",
    "    real_a_files = glob('%s*real_A*.npy'%subject)\n",
    "    real_b_files = glob('%s*real_B*.npy'%subject)\n",
    "    fake_b_files = glob('%s*fake_B*.npy'%subject)\n",
    "    \n",
    "    real_a_files.sort()\n",
    "    real_b_files.sort()\n",
    "    fake_b_files.sort()\n",
    "    \n",
    "    real_a = np.zeros((len(real_a_files), 128, 128, 3))\n",
    "    real_b = np.zeros((len(real_a_files), 128, 128, 3))\n",
    "    fake_b = np.zeros((len(real_a_files), 128, 128, 3))\n",
    "    for ii in range(len(real_a_files)):\n",
    "        real_a[ii]= np.load(real_a_files[ii]) \n",
    "        real_b[ii]= np.load(real_b_files[ii]) \n",
    "        fake_b[ii]= np.load(fake_b_files[ii])    \n",
    "\n",
    "    meanV1_img = nib.load('IITmean_V1.nii.gz')\n",
    "    meant1_img = nib.load('IITmean_t1.nii.gz')\n",
    "\n",
    "    meanV1 = meanV1_img.get_data()\n",
    "    meant1 = meant1_img.get_data()\n",
    "\n",
    "    b1.download_file(\"IXI_template/T_template3.nii.gz\", \"T_template3.nii.gz\")\n",
    "    b1.download_file(\"IXI_template/T_template_BrainCerebellumProbabilityMask.nii.gz\", \n",
    "                    \"T_template_BrainCerebellumProbabilityMask.nii.gz\")\n",
    "\n",
    "\n",
    "    skull_stripped_t1 = op.join('dwi-predictions',\n",
    "                                'skullstripped',\n",
    "                                '%s_skullstripped_t1.nii.gz'%subject) \n",
    "    \n",
    "    has_skull_stripped = False\n",
    "    for l in ll2:\n",
    "        k = l.key\n",
    "        if skull_stripped_t1 == k:\n",
    "            print(\"Downloading %s as skull-stripped\"%skull_stripped_t1)\n",
    "            b2.download_file(k, 'T1_BrainExtractionBrain.nii.gz')\n",
    "            has_skull_stripped = True\n",
    "\n",
    "    if not has_skull_stripped:\n",
    "        print(\"Running ANTS for skull stripping\")\n",
    "        ants_call = [\"antsBrainExtraction.sh\", \n",
    "                     \"-d\", \"3\", \"-a\", \"T1.nii.gz\",\n",
    "                     \"-e\" \"T_template3.nii.gz\", \n",
    "                     \"-m\", \"T_template_BrainCerebellumProbabilityMask.nii.gz\",\n",
    "                     \"-o\", \"T1_\"]\n",
    "\n",
    "        call(ants_call)            \n",
    "        b2.upload_file('T1_BrainExtractionBrain.nii.gz', \n",
    "                       skull_stripped_t1)\n",
    "\n",
    "    ants_brain_img = nib.load('T1_BrainExtractionBrain.nii.gz')\n",
    "    ants_brain = ants_brain_img.get_data()\n",
    "    print(\"Affine registration\")\n",
    "    transformed, affine = reg.affine_registration(meant1, ants_brain, meant1_img.affine, ants_brain_img.affine)   \n",
    "    print(\"SyN registration\")\n",
    "    warped_meant1, mapping = reg.syn_registration(meant1, ants_brain, moving_affine=meant1_img.affine, static_affine=ants_brain_img.affine, prealign=affine)                  \n",
    "    \n",
    "    print(\"Applying transformations\")\n",
    "\n",
    "    mapped = np.concatenate([mapping.transform(meanV1[..., 0])[..., np.newaxis], \n",
    "                             mapping.transform(meanV1[..., 1])[..., np.newaxis], \n",
    "                             mapping.transform(meanV1[..., 2])[..., np.newaxis]], -1) \n",
    "\n",
    "    DWI_img = nib.load('DTI-00.nii.gz')\n",
    "    DWI_affine = DWI_img.affine\n",
    "    resamp = np.concatenate([reg.resample(mapped[..., 0], DWI_img.get_data(), ants_brain_img.affine, DWI_affine)[..., np.newaxis], \n",
    "                             reg.resample(mapped[..., 1], DWI_img.get_data(), ants_brain_img.affine, DWI_affine)[..., np.newaxis], \n",
    "                             reg.resample(mapped[..., 2], DWI_img.get_data(), ants_brain_img.affine, DWI_affine)[..., np.newaxis]], -1)[:,:,1:-1]\n",
    "                         \n",
    "    resamp = np.moveaxis(resamp, 2, 0)\n",
    "\n",
    "    b1.download_file(op.join('IXI-Freesurfer-segmentations', subject, \"mri\", \"aparc+aseg.mgz\"), \n",
    "                           \"segmentation.mgz\")\n",
    "    mask_img = nib.load('segmentation.mgz')\n",
    "    mask_data = mask_img.get_data()\n",
    "    mask = (mask_data == 2) | (mask_data == 41)\n",
    "    \n",
    "    mask_resamp = reg.resample(mask.astype(float),\n",
    "                               DWI_img.get_data(), \n",
    "                               mask_img.affine, \n",
    "                               DWI_affine)[:,:,1:-1]\n",
    "\n",
    "    mask_resamp = np.moveaxis(mask_resamp, 2, 0)\n",
    "    mask = mask_resamp.astype(bool)\n",
    "    \n",
    "    print(\"Calculating fake error\")\n",
    "    angle_fake = np.rad2deg(np.arccos(np.clip((real_b[mask] * fake_b[mask]).sum(axis=-1), -1, 1)))\n",
    "    angle_fake = np.min(np.array([angle_fake, 180-angle_fake]), 0)\n",
    "    vol = np.nan * np.ones(real_b.shape[:3])\n",
    "    vol[mask] = angle_fake\n",
    "    \n",
    "    nib.save(nib.Nifti1Image(vol, DWI_affine), '%s_error_nn.nii.gz'%subject)\n",
    "    print(\"Uploading fake error\")\n",
    "    b2.upload_file('%s_error_nn.nii.gz'%subject, \n",
    "                   op.join(path, 'errors', \"%s_error_nn.nii.gz\"%subject)) \n",
    "    \n",
    "    print(\"Calculating template error\")\n",
    "    angle_template = np.rad2deg(np.arccos(np.clip((real_b[mask] * resamp[mask]).sum(axis=-1), -1, 1)))\n",
    "    angle_template = np.min(np.array([angle_template, 180-angle_template]), 0) \n",
    "\n",
    "    vol = np.nan * np.ones(real_b.shape[:3])\n",
    "    vol[mask] = angle_template\n",
    "    nib.save(nib.Nifti1Image(vol, DWI_affine), '%s_error_template.nii.gz'%subject)\n",
    "    print(\"Uploading template error\")\n",
    "    b2.upload_file('%s_error_template.nii.gz'%subject, \n",
    "                   op.join(path, 'errors', \"%s_error_template.nii.gz\"%subject)) \n",
    "    \n",
    "    print(\"Returning outputs\")\n",
    "    return angle_fake, angle_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ck.DockerImage(func=pdd_evaluate, \n",
    "                       github_installs=(\"git://github.com/arokem/pyAFQ.git@no_pathlib\"),\n",
    "                       base_image=\"arokem/ants:16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot = ck.Knot(name='ants-pdd-evaluate16_35',\n",
    "               docker_image=image,\n",
    "               memory=12000,\n",
    "               bid_percentage=100,\n",
    "               resource_type=\"SPOT\",\n",
    "               pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(set([foo.split('/')[-1].split('-')[0] for \n",
    "                foo in glob('/Users/arokem/data/mri2mri/t1_pdd_cosine_L1_unet128_T3_3d/*')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"t1_pdd_cosine_L1_unet128_T3_3d\"\n",
    "sigma = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [(experiment, subject, sigma) for subject in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t1_pdd_cosine_L1_unet128_T3_3d', 'IXI468', '0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures = knot.map(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knot.clobber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "j0 = knot.jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arrayProperties': {u'size': 78,\n",
       "  u'statusSummary': {u'FAILED': 0,\n",
       "   u'PENDING': 0,\n",
       "   u'RUNNABLE': 0,\n",
       "   u'RUNNING': 78,\n",
       "   u'STARTING': 0,\n",
       "   u'SUBMITTED': 0,\n",
       "   u'SUCCEEDED': 0}},\n",
       " 'attempts': [],\n",
       " 'status': u'PENDING',\n",
       " 'statusReason': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j0.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_futures.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = result_futures.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in foo:\n",
    "#     fig, ax = plt.subplots(1)\n",
    "#     ax.hist(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sub in ids:\n",
    "#     real_a_files = []\n",
    "#     real_b_files = []\n",
    "#     fake_b_files = []\n",
    "\n",
    "#     for k in glob('/Users/arokem/data/mri2mri/t1_pdd_cosine_L1_unet128_T3_3d/*%s*'%sub):\n",
    "#         if k.endswith('real_A.npy'):\n",
    "#             real_a_files.append(k)\n",
    "#         elif k.endswith('real_B.npy'):\n",
    "#             real_b_files.append(k)\n",
    "#         elif k.endswith('fake_B.npy'):\n",
    "#             fake_b_files.append(k)\n",
    "\n",
    "#     real_a_files.sort()\n",
    "#     real_b_files.sort()\n",
    "#     fake_b_files.sort()\n",
    "#     real_a = np.zeros((len(real_a_files), 128, 128, 3))\n",
    "#     real_b = np.zeros((len(real_a_files), 128, 128, 3))\n",
    "#     fake_b = np.zeros((len(real_a_files), 128, 128, 3))\n",
    "#     for ii in range(len(real_a_files)):\n",
    "#         real_a[ii]= np.load(real_a_files[ii]) \n",
    "#         real_b[ii]= np.load(real_b_files[ii]) \n",
    "#         fake_b[ii]= np.load(fake_b_files[ii])\n",
    "#     np.save('/Users/arokem/data/mri2mri/t1_pdd_cosine_L1_unet128_T3_3d/volumes/%s_real_A.npy'%sub, real_a, allow_pickle=False)\n",
    "#     np.save('/Users/arokem/data/mri2mri/t1_pdd_cosine_L1_unet128_T3_3d/volumes/%s_real_B.npy'%sub, real_b, allow_pickle=False)\n",
    "#     np.save('/Users/arokem/data/mri2mri/t1_pdd_cosine_L1_unet128_T3_3d/volumes/%s_fake_B.npy'%sub, fake_b, allow_pickle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
